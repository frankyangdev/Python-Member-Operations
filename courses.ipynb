{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 用Python学会员数据化运营--组队学习"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 课程介绍\n",
        "【主题】用Python学会员数据化运营  \n",
        "【工具】Jupyter Notebook、Excel  \n",
        "【学习基础】对python的numpy、pandas、time、sklearn库有一定了解  \n",
        "【学习时间】10-14天  \n",
        "【预计规模】50人左右  \n",
        "【小组成员】红星、志宾、健坤、雯静  \n",
        "【助教成员】  \n",
        "【资料形式】github开源代码，1次直播，数据化运营相关PPT介绍资料  \n",
        "【学习形式】组队学习，同步反馈并实时修正相关资料  \n",
        "\n",
        "【学习目的】  \n",
        "1、了解企业数据化运营中，运用数据工具对会员进行运营的思路和方法  \n",
        "2、了解RFM模型的运用  \n",
        "3、掌握Python处理数据的技巧  \n",
        "4、掌握Excel表的可视化图表及透视工具  \n",
        "\n",
        "【具体内容】  \n",
        "1、数据化运营概述，会员运营与用户运营概述  \n",
        "2、会员数据指标及分析模型介绍  \n",
        "3、案例练习：基于RFM的精细化用户管理  \n",
        "4、简单小结及模型延伸知识点介绍  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 一、会员数据化运营概述\n",
        "会员数据化运营，几乎是所有企业的必备运营工作，企业要生存必须有会员（客户），无论企业处于发展周期的哪个阶段、企业规模如何、企业性质如何，都是如此。会员数据化运营辅助于客户关系管理（CRM），可以用来解决以下几方面问题：\n",
        "* 会员的生命周期状态是什么？  \n",
        "* 会员的核心诉求是什么？  \n",
        "* 会员的转化习惯和路径是什么？\n",
        "* 会员的价值如何？  \n",
        "* 如何扩大市场覆盖、获得更多的新会员？  \n",
        "* 如何更好的维系老会员？  \n",
        "* 应该在什么时间、采取何种措施、针对哪些会员做哪些运营活动？  \n",
        "* 在特定运营目标下，应该如何制定会员管理策略（包括行为管理、体验管理、增值服务、信息管理、营销管理、客户关怀等）？   \n",
        "  \n",
        "传统的会员数据化运营更多聚焦在线上和线下的注册、购买会员，而无法获取线下会员在注册转化之前的用户数据。在大数据技术支持下，这种状态正在发生变化，借助于人工智能、深度学习等关键技术，可以将线上相对成熟的人脸识别、路径追踪等方面的应用逐步扩展到线下，这为线下会员完整生命周期的数据跟踪、识别和分析提供了基础。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 二、会员数据化运营关键指标\n",
        "会员数据化运营的关键指标包括会员**整体指标**、**营销指标**、**活跃度指标**、**价值度指标**、**终生价值指标**和**异动指标**。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1、会员整体指标\n",
        "**注册会员数**  \n",
        "注册会员数是指已经成为企业注册会员的数量。根据注册时间周期的不同，又可以细分为累计注册会员数、新增注册会员数等。\n",
        "\n",
        "**激活会员数**  \n",
        "激活会员相对于注册会员有一个特定的激活动作，该动作往往决定了用户是否真的会成为企业会员。常见的代表性动作包括：点击确认链接、手机验证、身份验证等。\n",
        "激活会员数是指已经注册的会员中有多少会员已经激活。根据激活时间周期的不同，又可以细分为累积激活会员数、新增激活会员数等。  \n",
        "激活会员数可以延伸出相对转化率指标：会员激活率。会员激活率指的是注册会员中已经完成激活的会员比例。\n",
        "\n",
        "**购买会员数**\n",
        "购买会员是真正给企业带来利润的群体。购买会员数是指有过购买行为的会员数量（企业也可以根据自身转化定义为其他要素，如付费会员数）。根据购买时间周期的不同，又可以细分为累积购买会员数、新增购买会员数等。\n",
        "\n",
        "购买会员数可以延伸出相对转化率指标。  \n",
        "注册--购买转化率：从注册到购买的会员转化比例。  \n",
        "激活--购买转化率：从激活到购买的会员转化比例。  \n",
        "在企业内部，如果转化周期和步骤比较长，还会细分出更多的转化状态指标，例如妥投会员、充值会员等。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2、会员营销指标\n",
        "**可营销会员数**\n",
        "可营销会员数是指整体会员中可通过一定方式进行会员营销以满足企业特定需求的会员数量。会员可营销的方式包括：手机号、邮箱、QQ号等具有可识别并可接触的信息点，具备这些信息中心的任何一种便可以形成可营销会员。\n",
        "\n",
        "**营销费用**\n",
        "会员营销费用一般包括营销媒介费用、优惠券费用和积分兑换费用3种。  \n",
        "（1）营销媒介费用  \n",
        "营销媒介费是特定营销媒介而产生的费用，例如短信费用、会员渠道推广费用、电子邮件费用等。  \n",
        "（2）优惠券费用  \n",
        "优惠券根据不同的使用条件和金额可以划分成多种，如30元现金券、50元店铺券等。企业促销时申请的优惠券费用是会员营销费用的重要组成部分。  \n",
        "（3）积分兑换费用  \n",
        "大部分网站都有会员积分系统，会员积分通常可以兑换成金额使用。如网站的积分兑换比例为20：1，即每20个积分可以兑换1元钱。在开展促销活动时，除了前期投入的广告费用、促销优惠券费用外，还会包含两种情况的积分费用：一部分是积分可以直接兑换成人民币来支付订单，另一部分是订单生成后会赠送一定数量的积分又形成可供兑换的金额（对企业来说是费用）。这两种情况的积分兑换都构成会员营销费用。\n",
        "\n",
        "**营销收入**\n",
        "会员营销收入是通过会员营销渠道和会员相关运营活动产生的收入，包括电子邮件、短信、会员通知、线下二维码、特定会员优惠码等。  \n",
        "在评估会员营销活动产生的收入时，直接通过特定有标记的渠道或促销码而成交的数据能清晰分辨出来。但是如果用户没有直接通过会员营销的接触点形成转化，那么这种收入是无法评估的。例如会员看到短信之后，又通过其他渠道形成订单。出现这种问题的根源是收入转化没有特定的标识符号用来做会员营销活动区分。因此，在做会员营销时，一定要尽量让用户有特定的标志，这样才能区分营销效果。  \n",
        "\n",
        "**用券会员/金额/订单比例**\n",
        "会员营销时，大多数情况都会使用优惠券，这不仅是促销销售的一种方式，也是识别不同会员订单来源的重要途径。用券类指标包括以下几种。  \n",
        "* 用券会员比例：使用优惠券下单的会员占总下单会员的比例。\n",
        "* 用券金额比例：使用优惠券下单的订单金额占总下单金额的比例。\n",
        "* 用券订单比例：使用优惠券下单量占总下单量的比例。\n",
        "  \n",
        "除此以外，还包括基于用券数据产生的用券用户平均订单金额、用券用户复购率等相关指标。\n",
        "\n",
        "**营销费率** \n",
        "营销费率是指会员营销费用占营销收入的比例。营销费率分析的目的是监督营销费用的支出情况，确保其不超出计划指标。  \n",
        "\n",
        "**每注册/订单/会员收入**\n",
        "监控会员营销的单位收入，是评估收益效率的重要指标，包括以下几种。\n",
        "* 每注册收入：每个注册用户带来多少收入。\n",
        "* 每订单收入：每个订单带来多少收入。\n",
        "* 每会员收入：每个会员带来多少收入。\n",
        "\n",
        "  \n",
        "**每注册/订单/会员成本**\n",
        "每注册/订单/会员成本单位成本的考量是精细化业务动作的关键指标之一，包括以下几种。  \n",
        "* 每注册成本：每获得一个注册用户需要多少成本。\n",
        "* 每订单成本：每获得一个订单需要多少成本。\n",
        "* 每会员成本：每获得一个会员需要多少成本。\n",
        "  \n",
        "除了上述单位成本指标外，还可能包括其他类型的成本，例如每挽回一个流失客户成本、每单位线索成本（例如获得一个联系方式）等。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3、会员活跃度指标\n",
        "**整体会员活跃度**\n",
        "整体会员活跃度用来评价当前所有会员的活跃情况，通常以会员动作或关键指标作为会员是否活跃的标识（如是否登录）。在这里，介绍一个会员活跃度矩阵，通过业务定义的关键因素来判断整体会员活跃度（因素及权重可根据企业自身实际情况定义）。  \n",
        "下表列出了所有会员关键动作节点和指标因素，并标识了每个因素的取值范围及权重。当用户登录/注册后（标识会员的前期条件），所有会员的行为都会被记录下来，形成会员数据日志。对每个会员的活跃度数据加权处理后求和，即可得到整体会员活跃度得分。\n",
        "整体会员活跃度=∑（注册*1+登录*1+验证*1+等级数*1+积分*1+…+商品评价*1）"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "|行为编码|取值范围|行为|行为类型|权重|\n",
        "|---|---|---|---|---|\n",
        "|Y/N|1|注册|账户行为|1|\n",
        "|Y/N|1|登陆|账户行为|1|\n",
        "|Y/N|>=1|EMAIL验证、手机验证、支付密码验证|账户行为|1|\n",
        "|等级数|>=1|升级会员|账户行为|1|\n",
        "|使用次数|>=1|使用积分|账户行为|1|\n",
        "|使用次数|>=1|使用优惠券|账户行为|1|\n",
        "|订阅次数|>=1|订阅信息|互动行为|1|\n",
        "|访问页面数|>=1|访问页面|互动行为|1|\n",
        "|搜索次数|>=1|搜索|互动行为|2|\n",
        "|查看次数|>=1|查看商品|互动行为|2|\n",
        "|次数|>=1|页面咨询|互动行为|1|\n",
        "|次数|>=1|收藏商品|互动行为|2|\n",
        "|次数|>=1|商品比价|互动行为|2|\n",
        "|次数|>=1|到货通知|互动行为|1|\n",
        "|次数|>=1|页面纠错|互动行为|1|\n",
        "|次数|>=1|加入购物车|订单行为|1|\n",
        "|次数|>=1|在线下单|订单行为|1|\n",
        "|次数|>=1|取消订单|订单行为|-1|\n",
        "|次数|>=1|换货订单|订单行为|-1|\n",
        "|次数|>=1|退货订单|订单行为|-1|\n",
        "|次数|>=1|订单完成|订单行为|1|\n",
        "|次数|>=1|参与活动|订单行为|1|\n",
        "|次数|>=1|商品评价|分享行为|1/0/-1|"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**举例**：某网站有两个用户，其中一个会员完成了1次注册、1次邮件验证（新会员默认是一级会员）、查看2次商品并有1次收藏行为；另一个会员是老会员（假设为二级会员），完成了1次登陆、1次页面咨询和1次退货订单。那么该网站（在假设只有2个会员的基础上）的用户活跃度为：  \n",
        "新会员（1*1+1*1+2*2+1*2+1*1）+老会员（1*1+1*1-1*1+2*1）=12  \n",
        "通过对每个用户的活跃度以及网站整体活跃度的积累可以发现网站用户活跃度变化趋势。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**每日/每周/每月活跃用户数**\n",
        "活跃用户中“活跃”的定义在不同的公司有不同的方法。最早活跃用户的概念从APP中产生，指的是每日应用上仍然启用的用户数量。活跃用户根据活跃周期的不同，可以定义如下。\n",
        "* 每日活跃用户：每天活跃用户的数量。  \n",
        "* 每周活跃用户：每周活跃用户的数量。  \n",
        "* 每月活跃用户：每月活跃用户的数量。\n",
        "  \n",
        "这3个指标在对应的时间周期内重复，即当有用户多次完成事件时会在周期内只计算一次。下面举例说明每日活跃用户和每周活跃用户的差异。下表显示了不同日期内，每日活跃用户的数量等于完成活跃动作或行为的用户数，而每周活跃用户数在1周内对用户进行去重。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "|时间|活跃用户|每日活跃用户|每周活跃用户|\n",
        "|---|---|---|---|\n",
        "|第1天|A|1|1|\n",
        "|第2天|AB|2|2|\n",
        "|第3天|  |0|2|\n",
        "|第4天|A|1|2|\n",
        "|第5天|  |0|2|\n",
        "|第6天|A|1|2|\n",
        "|第7天|A|1|2|"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4、会员价值度指标\n",
        "**会员价值分群**\n",
        "会员价值分群是以用户价值为出发点，通过特定模型或方法将会员分为几个群体或层级。常见的分群结果如：高、中、低，钻石、黄金、白银、青铜等。  \n",
        "会员价值分群并不是一个真正的指标，而是给用户打标签，该标签是用来显示用户的状态、层级和价值区分等。  \n",
        "\n",
        "**复购率**\n",
        "复购率是一定周期内购买2次或2次以上的会员比例。不同公司对复购率的定义有所差异，基本定义逻辑分为3种。以1个月为周期说明复购的定义。  \n",
        "* 第1种：1个月内购买2次或2次以上的会员。\n",
        "* 第2种：1个月内购买2次或2次以上、1个月之前有过购买行为的会员。\n",
        "* 第3种：1个月之前有购买行为、1个月之内又有购买行为的会员。\n",
        "  \n",
        "以上3种定义可根据自身情况调整，同时1个月的时间周期也可以根据商品或服务销售频次进行重新定义。\n",
        "\n",
        "**消费频次**\n",
        "消费频次和复购相关，二者都是重复消费指标。消费频次是将用户的消费频率，按照次数做统计，统计结果是在一定周期内消费了不同次数，例如2次、3至5次、6至10次、11次以上。该指标可以有效分析用户对于企业的消费粘性。  \n",
        "\n",
        "**最近一次购买时间**\n",
        "如字面意义，该指标也可以作为会员消费价值粘性的评价因素。如果会员距离上次的购买或消费时间过长，那么意味着用户可能处于沉默或者将要流失甚至已经流失的阶段，此时应该采取措施挽回用户。\n",
        "  \n",
        "**最近一次购买金额**\n",
        "最近一次购买金额和最近一次购买时间类似，该指标衡量的是用户最近一次购买或消费时的订单，该金额越大说明用户最近一次的消费能力越高。根据二八法则，20%的老会员会贡献80%的消费金额。\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5、会员终生价值指标\n",
        "**会员生命周期价值/订单量/平均订单价值**\n",
        "会员生命周期指标是从用户成为企业会员开始到现在的总数据统计值，该指标与任何时间周期无关，衡量的是用户完整生命周期内的价值。包括以下几种：\n",
        "  \n",
        "**会员生命周期价值**：用户整个生命周期内下单金额总和。\n",
        "**会员生命周期订单量**：用户整个生命周期内下单量总和。\n",
        "**会员生命周期平均订单价值**：用户整个生命周期内下单金额/下单量。\n",
        "  \n",
        "会员生命周期相关指标由于突破了时间的限制，能从整体上获得会员的宏观状态，因此是重要的宏观价值衡量指标。\n",
        "\n",
        "**会员生命周期转化率**\n",
        "会员生命周期转化率是指会员在完整生命周期内完成的订单和到达网站、企业、门店的次数比例。该指标衡量了用户是否具有较高的转化率。例如，用户一共到达网站100次，但是只有1次消费，那么会员生命周期转化率为1%。\n",
        "\n",
        "**会员生命周期剩余价值**\n",
        "会员生命周期剩余价值是一类预测性的指标，用来预测用户在其生命周期内还能产生多少价值。该指标可以细分出很多相关指标。例如：\n",
        "* 预期未来30天的会员转化率  \n",
        "* 预期生命周期剩余订单价值\n",
        "* 预期7天内下单数量\n",
        "* 预计下1个订单的订单金额\n",
        "* 下一次购买的商品名称\n",
        "  \n",
        "这种预测性的指标通常会基于特定的算法和模型做训练，然后预测未来的数据，其中回归和分类是主要预测性应用方法，在某些情况下也可以使用关联算法。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6、会员异动指标\n",
        "**会员流失率**\n",
        "会员流失是指会员不再购买或消费企业相关业务、商品和服务，会员流失率是指流失的会员数量与全部会员数量的比例。会员流失是一个正常现象，没有任何一个企业能够做到不让一个会员流失。但是会员流失意味着企业会失去相应的利润来源，因此需要从两个方面重点关注该指标：  \n",
        "*会员流失率的数值。*正常情况下会员流失率应该是一个比较小的比例，不同行业有不同的基准，各企业要制定符合行业特定的基准作为参考。  \n",
        "*会员流失率的走向。*尽管会员流失不可避免，但我们仍然希望流失用户的比例越小越好，因此需要关注流失率的走向。比较好的状态是流失率处于平稳或下降状态，如果出现流失率上升的情况，则需要引起警惕。\n",
        "\n",
        "**会员异动比**\n",
        "会员异动比是指新增会员与流失会员之间的比例关系，计算公式为  \n",
        "                                      **会员异动比=新增购买会员/流失会员**  \n",
        "如果会员异动比等于1，说明企业在一定周期内新增会员与流失会员数相等；如果大于1，说明新增会员多于流失会员，这是良好的发展状态；相反，如果小于1，说明会员增长不如流失快，企业将面临会员枯竭的危机。\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 三、会员数据化运营应用场景\n",
        "## 1、会员营销\n",
        "数据化运营应用于会员营销主要体现在以下几个方面：\n",
        "* 以信息化的方式建立基于会员的客户关系管理系统，促进所有会员数据的信息化。\n",
        "* 通过特定方法将普通用户拓展为企业用户，并提高新会员留存率。\n",
        "* 基于用户历史消费记录，挖掘出用户潜在消费需求及消费热点。\n",
        "* 基于历史数据，为会员营销活动提供策略指导和建议，促进精准营销活动的开展。\n",
        "* 从会员营销结果中寻找异常订单或转化，作为识别黄牛或VIP客户的参考。\n",
        "* 挖掘会员传播关系，找到口碑传播效应的关键节点。\n",
        "\n",
        "## 2、会员关怀\n",
        "数据化运营应用于会员关怀主要体现在以下几个方面：\n",
        "* 为预警时间设置阈值，自动触发应急处理机制。\n",
        "* 分析会员行为，为会员提供个性化、精准化和差异化服务。\n",
        "* 通过会员喜好分析，提高客户忠诚度、活跃度和粘性。\n",
        "* 通过会员分析，预防会员流失，并找到挽回已经流失会员的方法。\n",
        "* 基于会员群体行为，更好地划分会员群体属性并挖掘群体性特征。\n",
        "* 基于群体用户和内容相似度，发现有价值的会员互动方式。\n",
        "* 基于会员生命周期的关怀管理，促进用户终生价值最大化。\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 四、会员数据化运营分析模型\n",
        "这里介绍几个常用的会员分析模型。\n",
        "\n",
        "## 1、会员细分模型\n",
        "会员细分模型是将整体会员划分为不同的细分群体或类别，然后基于细分群体做管理、营销和关怀。会员细分模型常用于整体会员的宏观性分析以及探索性分析，通过细分建立初步认知，为下一步的分析和应用提供基本认知。会员细分也是做精准营销的基本前提。\n",
        "常用的细分模型包括：基于属性的方法、ABC分类法、聚类法等。\n",
        "\n",
        "**基于属性的方法**  \n",
        "会员细分可以基于现有会员属性，常用的细分属性包括：会员地域（例如北京、上海、武汉等）、产品类别（例如大家电、3C数码、图书等）、会员类别（例如大客户、普通客户、VIP客户等）、会员性别（例如男、女、未知）、会员消费等级（例如高价值会员、中价值会员、低价值会员）、会员等级（例如钻石、黄金、白银）等。这种细分方法可以直接利用现有会员数据库数据，无需做二次开发和计算，是一种比较简单且粗浅的方法。\n",
        "\n",
        "**ABC分类法**  \n",
        "ABC分类分（Activity Base Classification）是根据实物的主要特征做分类排列，从而实现区别对待、区别管理的一种方法。ABC法则是由帕累托二八法则衍生出来的一种法则。不同的是，二八法则强调的是抓住关键，ABC法则强调的是分清主次，并将管理对象划分为A、B、C三类。  \n",
        "在ABC分析法中，先将目标数据列倒序排序，然后做累计百分比统计，最后将得到的累积百分比按照下面的比例至划分为A、B、C三类。  \n",
        "* A类因素：发生累积频率为0%-80%，是主要影响因素。\n",
        "* B类因素：发生累积频率为80%-90%，是次要影响因素。\n",
        "* C类因素：发生累积频率为90%-100%，是一般影响因素。\n",
        "\n",
        "下面以示例数据说明如何使用ABC分类法对会员进行细分。  \n",
        "（1）建立一个二维表格数据，数据中包括会员ID和订单金额（或其他关键指标）两列  \n",
        "（2）二维表格数据按照订单金额做倒序排序  \n",
        "（3）对订单金额列进行累积百分比统计  \n",
        "  \n",
        "按照A、B、C划分标准将会员划分为不同的分类，得到下表所示数据：  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "|用户ID|订单金额|订单金额累积百分比|ABC分类|\n",
        "|---|---|---|---|\n",
        "|228355|55960719|29.44%|A|\n",
        "|260835|28382998|44.36%|A|\n",
        "|231664|22995042|56.46%|A|\n",
        "|204075|20582024|67.29%|A|\n",
        "|189610|16093666|75.75%|A|\n",
        "|205016|14543748|83.40%|B|\n",
        "|327963|14393922|90.97%|C|\n",
        "|189334|13752004|98.21%|C|\n",
        "|234680|3382530|99.99%|C|\n",
        "|266283|28119|100.00%|C|\n",
        "\n",
        "**聚类法**  \n",
        "使用聚类法做会员细分是常用的非监督方法，该方法无需任何先验经验，只需要制定要划分的群体数量即可。关于聚类算法，这里不做延伸介绍。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2、会员价值度模型\n",
        "会员价值度，作为评价用户的价值情况，是区分用户价值的重要模型和参考依据，也是衡量不同营销效果的关键指标之一。价值度模型一般基于交易行为产生，衡量的是有实体转化价值的行为。常用的价值度模型是**RFM模型**。  \n",
        "RFM模型是根据会员最近一次购买时间R（Recency）、购买频率F（Frequency）、购买金额M（Monetary）计算出RFM得分，通过这3个维度来评估客户的订单活跃价值，常用来做客户分群或价值区分。该模型常用于电子商务（即交易类）企业的会员分析。  \n",
        "RFM模型基于一个固定时间点来做模型分析，因此今天做的RFM得分与7天前做的结果可能不一样，原因是每个客户在不同的时间节点所得到的数据不同。以下是RFM模型的基本实现过程。  \n",
        "（1）设置要做计算时的时间节点（例如2021-07-07），用来做基于该时间的数据选取和计算。  \n",
        "（2）在会员数据库中，以今天为时间界限向前倒推固定周期（例如一年），得到包含每个会员的会员ID、订单时间、订单金额的原始数据集。一个会员可能会产生多条订单记录。  \n",
        "（3）数据预处理。从订单时间中找到各个会员距离截止时间节点最近的订单时间作为最近购买时间；以会员ID为维度统计每个用户的订单数量作为购买频率；将用户多个订单的订单金额求和得到总订单金额。由此得到的R、F、M三个原始数据。  \n",
        "（4）R、F、M分区。对于F和M变量来讲，值越大代表购买频率越高、订单金额越高；但对于R来讲，值越小代表离截止时间节点越近，因此值越好。对R、F、M分别使用五分位（三分位也可以，分位数越多划分的越详细）法做数据分区。需要注意的是，对于R来讲需要倒过来划分，离截止时间越近的值，划分越大。这样得到每个用户的R、F、M三个变量的分位数值。  \n",
        "（5）将三个值组合或相加得到总的RFM得分。对于RFM总得分的计算，有两种方式，一种是直接将三个值拼接在一起，例如RFM得分为312、333、132等。另一种是直接将三个值相加，求得一个新的汇总值，例如RFM得分为6、9、6。 \n",
        "在得到不同的会员的R、F、M后，根据步骤5产生的两种结果，有两种应用思路。  \n",
        "* 思路1：基于三个维度值做用户群体划分和解读，对用户的价值度做分析。例如得分为212的会员往往购买频率较低，针对购买频率低的客户应该定期发送促销活动的邮件；得分为321的会员虽然购买频率高，但是订单金额低，这样的客户具有较高的购买粘性，可以考虑通过关联或者搭配销售的方式提升订单金额。\n",
        "* 思路2：基于RFM的汇总得分评估所有会员的价值度情况，并可以进行价值度排名。同时，该得分还可以作为输入维度与其他维度一起作为其他数据分析和挖掘模型的输入变量，为分析建模提供基础。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3、会员流失预测模型\n",
        "会员流失预测模型，用来预测会员是否流失，是做会员生命周期的重要预防性应用。做会员流失模型的关键因素之一，是要定义好“流失”，即处于何种状态、具备哪些特征的会员属于流失会员。另外，流失也要区分永久性流失和临时性流失。常见的关于流失的状态，定义如下：\n",
        "* 会员已经退订公司的促销活动\n",
        "* 会员打电话要求将自己的信息加入通知黑名单\n",
        "* 会员已经连续6个月没有登陆过网站\n",
        "* 针对会员发送的关怀激励活动后没有得到任何有效的反馈和互动\n",
        "* 会员最近1年内没有任何订单\n",
        "上述流失状态可以归为两类：一类是会员有明确的表达，不再希望接收到公司的相关信息；另一类是会员没有明确的标识，但是在业务关注的主要领域内，没有得到有效反馈。  \n",
        "会员流失预测模型的实现方法属于分类算法，常用算法包括逻辑回归、支持向量机、随机森林等有关这些算法的具体选择问题，这里不另外进行拓展。  \n",
        "在做会员流失预警模型时，需要注意以下几个问题。  \n",
        "* 流失会员的样本分类一定是少数类，需要注意处理样本不均衡的问题。\n",
        "* 对于流失会员的预测结果，得到概率性的输出可以结合流失预测标签一起应用，因为业务方可以基于概率，再结合业务经验做判断。\n",
        "* 对于参与训练模型的维度变量的选择，一定要结合业务经验，因为业务方对于特定场景的判断是影响训练模型和应用结果的关键因素之一。\n",
        "* 输入的维度变量中一定要包含发生转化前的行为数据。假如业务定义为最近6个月没有订单的客户为流失客户，那么在做预测模型时，需要将用户的匿名访问、登录、页面浏览、搜索、活动咨询等转化前的数据考虑在内，而不能只考虑订单转化本身。\n",
        "* 会员流失预警模型不是一次性的，而是周期性监视和运行的，例如每天每周或至少是每月。\n",
        "  \n",
        "通过会员流失模型，得到每个会员是否属于流失标签后，可以将该结果给到会员运营人员，运营人员一般会根据业务经验做二次审查和确认，然后再通过会员挽回激励等机制，提升会员的忠诚度，延缓或防止会员流失。而关于如何挽回以及激励的问题，通常需要数据参与来帮助运营人员制定相应的策略，例如，在合适的时间以恰当的方式提供个性化的内容给特定会员。这些都需要数据的支持。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4、会员特征分析模型\n",
        "会员特征分析模型是针对现有会员做特征分析。会员特征分析模型提供的结果可能是模糊的，也可能是明确的，例如：\n",
        "* 明确的特征，这类特征模型提供了业务所要行动的细节要素，是一种具有极高落地价值的数据分析工作。\n",
        "* 模糊的特征，它只有数据分析结果，未提供详细的动作因素，仅仅指明了下一步行动方向和目标。\n",
        "  \n",
        "会员特征分析主要应用于以下两种业务场景：  \n",
        "第1种是在没有任何前期经验或特定目标下触发，希望通过整体特征分析了解会员全貌，在这种模式下可以通过一定方法先将用户划分为几个类别，然后再做基于类别的特征分析，常用的实现方法和应用包括以下两种。  \n",
        "* 聚类。通过聚类将用户划分为几个群组，然后再分析不同群组的典型特征和群组间的差异性。例如，公司的总体会员具有哪些特征？模型结果通过聚类方法将会员划分为三类，然后每个类别都有各自显著性特征，会员部门可根据不同类别做特定分析并指定群体性策略。\n",
        "* 统计分析。先对整体用户做统计分析，包括描述性分析，频数分布等了解整体数据概括。\n",
        "  \n",
        "第2种是有明确的业务方向，希望找到能达到事件目标的会员特征，用于做进一步的会员运营，对于这类分析模型常用的实现方法和应用包括以下三种。\n",
        "* **分类**。利用分类规则，例如决策树，找到符合目标的关键变量及对应的变量值，进而确定会员特征。例如：收入大于5400元，最近购买时间是5个月之前，总订单金额在4300元以下的会员，最可能购买商品。\n",
        "* **关联**。使用关联规则，找到不同属性项目间的关联发生或序列发生关系，然后将会员的属性特征（频繁项集）提供给运营人员。例如：购买X商品的客户一般来自上海，购买频率为一周三次，客单价为100元以下。\n",
        "* **异常检测**。使用非监督式的异常检测方法，从一堆数据中找到异常数据样本，然后将这些数据样本特征提供给运营人员做进一步确认和审查。例如：异常客户的特征往往是，每次订单的商品数量超过4件，地域集中在江苏和浙江一般拥有超过三个以上的子账户。\n",
        "  \n",
        "会员特征分析模型输出的上述两类结果，第1类结果往往作为辅助性、启发性和提示性结果，用于为运营提供进一步业务动作的思考，这种一般开始于数据工作项目的开始或业务方对数据主题的先验经验不足的情况下。第2类结果则可以作为运营下一步动作的直接触点。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5、营销响应预测模型\n",
        "营销响应预测模型是针对营销活动展开的，通常在做会员营销活动之前。通过营销响应预测模型分析，找到可能响应活动的会员特征及整体响应的用户比例数量和可能带来的销售额，这对于在会员营销之前的有关策略制定的辅助价值非常明显。  \n",
        "营销响应预测模型的实施一般采用分类算法。常用算法，包括逻辑回归、支持向量机、随机森林等，有关这些算法的具体选择问题，这里不再详细阐述。  \n",
        "在做营销响应模型之前，需要先收集训练所需要的数据集。  \n",
        "（1）从所有会员中随机选择一定量的会员样本，具体数量要根据企业实际情况而定，一般情况下至少需要有1000条数据以上，同时要兼顾总体会员数量，才能满足模型训练的需要。  \n",
        "（2）针对选择的会员样本，通过一定媒介和渠道发送营销活动信息，例如手机短信、电子邮件等。需要注意的是，一定要记录好营销活动发送的时间频率信息等关键运营要素，这些需要与后期的实施保持一致。  \n",
        "（3）收集营销活动数据，在收集数据时需要注意数据收集的周期。通常情况下，一般电子邮件的有效周期为1~7天，时间过短可能无法被用户看到；手机短信的有效期一般是1天，时间太长，用户一般会忽略。  \n",
        "经过上述步骤收集到分类所需的样本集之后，接着就需要通过分类模型做营销响应预测，这是典型的二分类问题。在做营销响应模型训练时，也需要注意在前面会员流失预测模型提到的问题，二者在很多方面都有共通性。  \n",
        "通过营销响应预测模型得到的结果一般包括以下两个方向。  \n",
        "基于模型找到最可能产生购买转化行为的会员规则特征，例如最近一次购买时间在三个月以内，会员等级为三级以上，总订单金额大于3000，订单量大于10的客户，通过这些条件直接从数据库中筛选对应的会员列表，并可以对该列表中的会员发送营销活动信息。  \n",
        "基于模型预测可能产生的订单转化数量、转化率（例如选择10000个客户，会有4000个客户产生转化）以及有转化客户的客单价（通过训练样本及选择有转化客户，然后用订单金额/会员量计算得到）大体计算出此次发送能得到的营销收入，这些信息可以作为此次营销活动计划提报的数据量化指标和资源申请的数据支持。  \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 五、基于RFM的精细化用户管理\n",
        "## 1、案例背景\n",
        "用户价值细分是了解用户价值度的重要途径，而销售型公司中对于订单交易尤为关注，因此基于订单交易的价值度模型将更适合运营需求。针对交易数据分析的常用模型是RFM模型，该模型不仅简单、容易理解，且业务落地能力非常强。因此，本节将基于该模型做数据分析和应用。在RFM的结果中，业务部门希望不仅能对用户做分组，还希望能将每个组的用户特征概括和总结出来，这样便于后续精细化运营不同的客户群体，且根据不同群体做定制化或差异性的营销和关怀。  \n",
        "基于业务部门的用户分群需求，我们计划将RFM的3个维度分别作3个区间的离散化，这样出来的用户群体最大有3*3*3=27个。如果划分区间过多则不利于用户群体的拆分，区间过少则可能导致每个特征上的用户区分不显著。  \n",
        "从交付结果看，给业务部门做运营的分析结果都要导出成Excel文件，用于做后续分析和二次加工使用。另外，RFM的结果还会供其他模型的建模使用，RFM本身的结果可以作为新的局部性特征，因此数据的输出需要有本地文件和写数据库两种方式。  \n",
        "本节案例选择了4年的订单数据，这样可以从不同的年份对比不同时间下各个分组的绝对值变化情况，方便了解会员的波动。本节案例的输入源数据sales.xlsx和源代码chapter5_code.ipynb，程序输出RFM得分数据写入本地文件sales_rfm_score.xlsx。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2、案例主要应用技术\n",
        "本案例使用的库包括time、numpy和pandas。在实现RFM组合时，我们使用sklearn的随机森林库来计算RFM的权重，在结果展示的时候主要使用Excel的可视化图表方式。\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3、案例数据\n",
        "案例数据是某企业从2015年到2018年共4年的用户订单抽样数据，数据来源于销售系统。数据在Excel中包含5个sheet，前4个sheet以年份为单位存储为单个sheet中，最后一张会员等级表为用户的等级表。  \n",
        "前4张表的数据概要如下：  \n",
        "* 特征变量数：4\n",
        "* 数据记录数：30774、41278、50839、81349\n",
        "* 是否有NA值：有 \n",
        "* 是否有异常值：有\n",
        "  \n",
        "具体数据特征如下：\n",
        "* 会员ID：每个会员的ID唯一，由纯数字组成。\n",
        "* 提交日期：订单日提交日期。\n",
        "* 订单号：订单ID，每个订单的ID唯一，由纯数字组成。\n",
        "* 订单金额：订单金额，浮点型数据。\n",
        "  \n",
        "会员等级表中是所有会员的会员ID对应会员等级的情况，包括以下两个字段。  \n",
        "* 会员ID：该ID可与前面的订单表中的会员ID关联。\n",
        "* 会员等级：会员等级以数字区分，数字越大，级别越高。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4、案例过程\n",
        "（1）导入库"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install openpyxl\r\n",
        "!pip3 install --user xlsxwriter"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.0.7)\n",
            "Requirement already satisfied: et-xmlfile in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from openpyxl) (1.1.0)\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.1-py3-none-any.whl (148 kB)\n",
            "\u001b[K     |████████████████████████████████| 148 kB 32.2 MB/s eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.1\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Python版本3.7.4\n",
        "#引入各类必须的库,numpy==1.17.2,pandas==0.25.1\n",
        "import time \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#引入机器学习包sklearn,sklearn==0.21.3\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1629180295316
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里用到4个库：time、numpy、pandas、sklearn  \n",
        "* time：用来记录插入数据库时的当前日期\n",
        "* numpy：用来做基本数据处理等\n",
        "* pandas：有关日期转换、数据格式化处理、主要RFM计算过程等\n",
        "* sklearn：使用其中的随机森林库\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "（2）读取数据"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install openpyxl"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (3.0.7)\r\n",
            "Requirement already satisfied: et-xmlfile in /anaconda/envs/azureml_py36/lib/python3.6/site-packages (from openpyxl) (1.1.0)\r\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#创建sheet_names列表，与表格数据相对应，方便后续处理\n",
        "sheet_names = ['2015','2016','2017','2018','会员等级']\n",
        "#利用pandas库中的read_excel()函数，根据每一列的sheet_names,从第一行到最后一行依次读取每一行的数据作为sheet_datas\n",
        "sheet_datas = [pd.read_excel('./data/sales.xlsx',sheet_name=i,engine='openpyxl') for i in sheet_names]#必须要保证与jupyter在同一个目录下才可以直接read_excel（'name.xlsx'）"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1629180400072
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "先定义一个列表sheet_names，目的是方便后续制定sheet名称；然后再通过列表推导式配合pandas的read_excel批量读取sales.xlsx中所有的数据到列表中，形成sheet_datas。该过程会比较耗时。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "（3）数据审查\n",
        "* 前N条数据主要查看不同数据列的数据格式，尤其是有特定转换操作之后是否符合源数据文件的格式或得到目标转换要求，以及数据的长度、组成规律、类型等是否与真实数据一致。\n",
        "* 数据描述性信息主要分析数据分布规律，包括记录数、极值、标准差、分位数结果等，可用于数据集的使用模型、极值的处理等后续计算的辅助判断依据。\n",
        "* 缺失值信息帮助我们判断数量以及后续应对策略。\n",
        "* 数据类型用于判断目标类型当前状态，以及后续是否需要做特殊处理。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#对表格数据做显示，以审查一下我们的数据是否有误\n",
        "for each_name,each_data in zip(sheet_names,sheet_datas):#zip() 函数用于将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表。\n",
        "    print('[data summary for {0:=^50}]'.format(each_name))#显示各年份之间的分割线\n",
        "    print('Overview:','\\n',each_data.head(4))# 展示数据前4条\n",
        "    print('DESC:','\\n',each_data.describe())# 数据描述性信息\n",
        "    print('NA records',each_data.isnull().any(axis=1).sum()) # 缺失值记录数\n",
        "    print('Dtypes',each_data.dtypes) # 数据类型"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[data summary for =======================2015=======================]\n",
            "Overview: \n",
            "            会员ID           订单号       提交日期    订单金额  NaN  Unnamed: 5  Unnamed: 6  \\\n",
            "0  1.527800e+10  3.000305e+09 2015-01-01   499.0  NaN         NaN         NaN   \n",
            "1  3.923638e+10  3.000306e+09 2015-01-01  2588.0  NaN         NaN         NaN   \n",
            "2  3.872204e+10  3.000642e+09 2015-01-01   498.0  NaN         NaN         NaN   \n",
            "3  1.104964e+10  3.000799e+09 2015-01-01  1572.0  NaN         NaN         NaN   \n",
            "\n",
            "   Unnamed: 7  Unnamed: 8  None.1  \n",
            "0         NaN         NaN     NaN  \n",
            "1         NaN         NaN     NaN  \n",
            "2         NaN         NaN     NaN  \n",
            "3         NaN         NaN     NaN  \n",
            "DESC: \n",
            "                会员ID           订单号           订单金额  NaN  Unnamed: 5  Unnamed: 6  \\\n",
            "count  3.077400e+04  3.077400e+04   30774.000000  0.0         0.0         0.0   \n",
            "mean   2.918779e+10  4.020414e+09     960.991161  NaN         NaN         NaN   \n",
            "std    1.385333e+10  2.630510e+08    2068.107231  NaN         NaN         NaN   \n",
            "min    2.670000e+02  3.000305e+09       0.500000  NaN         NaN         NaN   \n",
            "25%    1.944122e+10  3.885510e+09      59.000000  NaN         NaN         NaN   \n",
            "50%    3.746545e+10  4.117491e+09     139.000000  NaN         NaN         NaN   \n",
            "75%    3.923593e+10  4.234882e+09     899.000000  NaN         NaN         NaN   \n",
            "max    3.954613e+10  4.282025e+09  111750.000000  NaN         NaN         NaN   \n",
            "\n",
            "       Unnamed: 7  Unnamed: 8  None.1  \n",
            "count         0.0         0.0     0.0  \n",
            "mean          NaN         NaN     NaN  \n",
            "std           NaN         NaN     NaN  \n",
            "min           NaN         NaN     NaN  \n",
            "25%           NaN         NaN     NaN  \n",
            "50%           NaN         NaN     NaN  \n",
            "75%           NaN         NaN     NaN  \n",
            "max           NaN         NaN     NaN  \n",
            "NA records 61370\n",
            "Dtypes 会员ID                 float64\n",
            "订单号                  float64\n",
            "提交日期          datetime64[ns]\n",
            "订单金额                 float64\n",
            "NaN                  float64\n",
            "Unnamed: 5           float64\n",
            "Unnamed: 6           float64\n",
            "Unnamed: 7           float64\n",
            "Unnamed: 8           float64\n",
            "None.1               float64\n",
            "dtype: object\n",
            "[data summary for =======================2016=======================]\n",
            "Overview: \n",
            "            会员ID           订单号       提交日期    订单金额  NaN  Unnamed: 5  Unnamed: 6\n",
            "0  3.928812e+10  4.282026e+09 2016-01-01    76.0  NaN         NaN         NaN\n",
            "1  3.929381e+10  4.282038e+09 2016-01-01  7599.0  NaN         NaN         NaN\n",
            "2  2.759634e+10  4.282039e+09 2016-01-01   802.0  NaN         NaN         NaN\n",
            "3  1.511148e+10  4.282044e+09 2016-01-01    65.0  NaN         NaN         NaN\n",
            "DESC: \n",
            "                会员ID           订单号           订单金额  NaN  Unnamed: 5  Unnamed: 6\n",
            "count  4.127800e+04  4.127800e+04   41277.000000  0.0         0.0         0.0\n",
            "mean   2.908415e+10  4.313583e+09     957.106694  NaN         NaN         NaN\n",
            "std    1.389468e+10  1.094572e+07    2478.560036  NaN         NaN         NaN\n",
            "min    8.100000e+01  4.282026e+09       0.100000  NaN         NaN         NaN\n",
            "25%    1.934990e+10  4.309457e+09      59.000000  NaN         NaN         NaN\n",
            "50%    3.730339e+10  4.317545e+09     147.000000  NaN         NaN         NaN\n",
            "75%    3.923182e+10  4.321132e+09     888.000000  NaN         NaN         NaN\n",
            "max    3.954554e+10  4.324911e+09  174900.000000  NaN         NaN         NaN\n",
            "NA records 82126\n",
            "Dtypes 会员ID                 float64\n",
            "订单号                  float64\n",
            "提交日期          datetime64[ns]\n",
            "订单金额                 float64\n",
            "NaN                  float64\n",
            "Unnamed: 5           float64\n",
            "Unnamed: 6           float64\n",
            "dtype: object\n",
            "[data summary for =======================2017=======================]\n",
            "Overview: \n",
            "            会员ID           订单号       提交日期    订单金额  NaN  Unnamed: 5  Unnamed: 6\n",
            "0  3.876529e+10  4.324911e+09 2017-01-01  1799.0  NaN         NaN         NaN\n",
            "1  3.930583e+10  4.324911e+09 2017-01-01   369.0  NaN         NaN         NaN\n",
            "2  3.419099e+10  4.324911e+09 2017-01-01   189.0  NaN         NaN         NaN\n",
            "3  3.898633e+10  4.324911e+09 2017-01-01   169.0  NaN         NaN         NaN\n",
            "DESC: \n",
            "                会员ID           订单号           订单金额  NaN  Unnamed: 5  Unnamed: 6\n",
            "count  5.083900e+04  5.083900e+04   50839.000000  0.0         0.0         0.0\n",
            "mean   2.882368e+10  4.332466e+09     963.587872  NaN         NaN         NaN\n",
            "std    1.409416e+10  4.404350e+06    2178.727261  NaN         NaN         NaN\n",
            "min    2.780000e+02  4.324911e+09       0.300000  NaN         NaN         NaN\n",
            "25%    1.869274e+10  4.328415e+09      59.000000  NaN         NaN         NaN\n",
            "50%    3.688044e+10  4.331989e+09     149.000000  NaN         NaN         NaN\n",
            "75%    3.923020e+10  4.337515e+09     898.000000  NaN         NaN         NaN\n",
            "max    3.954554e+10  4.338764e+09  123609.000000  NaN         NaN         NaN\n",
            "NA records 102079\n",
            "Dtypes 会员ID                 float64\n",
            "订单号                  float64\n",
            "提交日期          datetime64[ns]\n",
            "订单金额                 float64\n",
            "NaN                  float64\n",
            "Unnamed: 5           float64\n",
            "Unnamed: 6           float64\n",
            "dtype: object\n",
            "[data summary for =======================2018=======================]\n",
            "Overview: \n",
            "            会员ID           订单号       提交日期    订单金额  NaN  Unnamed: 5  Unnamed: 6\n",
            "0  3.922969e+10  4.338764e+09 2018-01-01  3646.0  NaN         NaN         NaN\n",
            "1  3.929367e+10  4.338764e+09 2018-01-01  3999.0  NaN         NaN         NaN\n",
            "2  3.505965e+10  4.338764e+09 2018-01-01    10.1  NaN         NaN         NaN\n",
            "3  1.084397e+06  4.338770e+09 2018-01-01   828.0  NaN         NaN         NaN\n",
            "DESC: \n",
            "                会员ID           订单号           订单金额  NaN  Unnamed: 5  Unnamed: 6\n",
            "count  8.134900e+04  8.134900e+04   81348.000000  0.0         0.0         0.0\n",
            "mean   2.902317e+10  4.348372e+09     966.582792  NaN         NaN         NaN\n",
            "std    1.404116e+10  4.183774e+06    2204.969534  NaN         NaN         NaN\n",
            "min    2.780000e+02  4.338764e+09       0.000000  NaN         NaN         NaN\n",
            "25%    1.902755e+10  4.345654e+09      60.000000  NaN         NaN         NaN\n",
            "50%    3.740121e+10  4.349448e+09     149.000000  NaN         NaN         NaN\n",
            "75%    3.923380e+10  4.351639e+09     899.000000  NaN         NaN         NaN\n",
            "max    3.954614e+10  4.354235e+09  174900.000000  NaN         NaN         NaN\n",
            "NA records 163124\n",
            "Dtypes 会员ID                 float64\n",
            "订单号                  float64\n",
            "提交日期          datetime64[ns]\n",
            "订单金额                 float64\n",
            "NaN                  float64\n",
            "Unnamed: 5           float64\n",
            "Unnamed: 6           float64\n",
            "dtype: object\n",
            "[data summary for =======================会员等级=======================]\n",
            "Overview: \n",
            "           会员ID  会员等级  Unnamed: 2  Unnamed: 3\n",
            "0       100090     3         NaN         NaN\n",
            "1  10012905801     1         NaN         NaN\n",
            "2  10012935109     1         NaN         NaN\n",
            "3  10013498043     1         NaN         NaN\n",
            "DESC: \n",
            "                会员ID           会员等级  Unnamed: 2  Unnamed: 3\n",
            "count  1.543850e+05  154385.000000         0.0         0.0\n",
            "mean   2.980055e+10       2.259701         NaN         NaN\n",
            "std    1.365654e+10       1.346408         NaN         NaN\n",
            "min    8.100000e+01       1.000000         NaN         NaN\n",
            "25%    2.213894e+10       1.000000         NaN         NaN\n",
            "50%    3.833022e+10       2.000000         NaN         NaN\n",
            "75%    3.927932e+10       3.000000         NaN         NaN\n",
            "max    3.954614e+10       5.000000         NaN         NaN\n",
            "NA records 154385\n",
            "Dtypes 会员ID            int64\n",
            "会员等级            int64\n",
            "Unnamed: 2    float64\n",
            "Unnamed: 3    float64\n",
            "dtype: object\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1629180408517
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用for循环，配合zip函数来读取sheet_names和sheet_datas中的每个值，然后分别输出以下内容：  \n",
        "* 数据展示：使用数据框的head方法，显示前4条数据\n",
        "* 描述性信息：使用数据框的describe方法，显示所有的描述性统计结果\n",
        "* 缺失值记录：使用数据框的isnull().any(axis=1)来判断含有缺失值的记录，然后用sum获取总记录数\n",
        "* 数据类型：使用数据框的dtypes方法获取所有字段数据类型信息。\n",
        "  \n",
        "输出结果如上面代码cell所示。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "通过上述结果我们可以得到如下结论：  \n",
        "* 每个sheet中的数据都能正常读取和识别，无任何错误。\n",
        "* 日期列（提交日期）已经被自动识别为日期格式，这省去了后期做转换的过程。\n",
        "* 订单金额的分布是不均匀的，里面有明显的极大值，例如2016年的数据中，最大值为174900，最小值仅为0.1。这样的分布状态，数据会受到极值影响。\n",
        "* 订单中的最小值竟然包括0、0.1这样的金额，显然不是正常订单。经过与业务方沟通后确认，最大值的订单金额有效，通常是客户一次性购买多个大家电商品；而订单金额为0.1这类是使用优惠券支付的订单，并没有实际意义。除此之外，所有低于1元的订单均有这个问题，因此需要在后续处理中去掉。\n",
        "* 有的表中存在缺失值记录，但数量不多，因此选择丢弃或填充都可以。\n",
        "  \n",
        "（4）数据预处理。\n",
        "去除缺失值和异常值："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "sheet_datas"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "[               会员ID           订单号       提交日期    订单金额  NaN  Unnamed: 5  \\\n 0      1.527800e+10  3.000305e+09 2015-01-01   499.0  NaN         NaN   \n 1      3.923638e+10  3.000306e+09 2015-01-01  2588.0  NaN         NaN   \n 2      3.872204e+10  3.000642e+09 2015-01-01   498.0  NaN         NaN   \n 3      1.104964e+10  3.000799e+09 2015-01-01  1572.0  NaN         NaN   \n 4      3.503875e+10  3.000822e+09 2015-01-01    10.1  NaN         NaN   \n ...             ...           ...        ...     ...  ...         ...   \n 61365           NaN           NaN        NaT     NaN  NaN         NaN   \n 61366           NaN           NaN        NaT     NaN  NaN         NaN   \n 61367           NaN           NaN        NaT     NaN  NaN         NaN   \n 61368           NaN           NaN        NaT     NaN  NaN         NaN   \n 61369           NaN           NaN        NaT     NaN  NaN         NaN   \n \n        Unnamed: 6  Unnamed: 7  Unnamed: 8  None.1  \n 0             NaN         NaN         NaN     NaN  \n 1             NaN         NaN         NaN     NaN  \n 2             NaN         NaN         NaN     NaN  \n 3             NaN         NaN         NaN     NaN  \n 4             NaN         NaN         NaN     NaN  \n ...           ...         ...         ...     ...  \n 61365         NaN         NaN         NaN     NaN  \n 61366         NaN         NaN         NaN     NaN  \n 61367         NaN         NaN         NaN     NaN  \n 61368         NaN         NaN         NaN     NaN  \n 61369         NaN         NaN         NaN     NaN  \n \n [61370 rows x 10 columns],\n                会员ID           订单号       提交日期    订单金额  NaN  Unnamed: 5  \\\n 0      3.928812e+10  4.282026e+09 2016-01-01    76.0  NaN         NaN   \n 1      3.929381e+10  4.282038e+09 2016-01-01  7599.0  NaN         NaN   \n 2      2.759634e+10  4.282039e+09 2016-01-01   802.0  NaN         NaN   \n 3      1.511148e+10  4.282044e+09 2016-01-01    65.0  NaN         NaN   \n 4      3.889659e+10  4.282051e+09 2016-01-01    95.0  NaN         NaN   \n ...             ...           ...        ...     ...  ...         ...   \n 82121           NaN           NaN        NaT     NaN  NaN         NaN   \n 82122           NaN           NaN        NaT     NaN  NaN         NaN   \n 82123           NaN           NaN        NaT     NaN  NaN         NaN   \n 82124           NaN           NaN        NaT     NaN  NaN         NaN   \n 82125           NaN           NaN        NaT     NaN  NaN         NaN   \n \n        Unnamed: 6  \n 0             NaN  \n 1             NaN  \n 2             NaN  \n 3             NaN  \n 4             NaN  \n ...           ...  \n 82121         NaN  \n 82122         NaN  \n 82123         NaN  \n 82124         NaN  \n 82125         NaN  \n \n [82126 rows x 7 columns],\n                 会员ID           订单号       提交日期    订单金额  NaN  Unnamed: 5  \\\n 0       3.876529e+10  4.324911e+09 2017-01-01  1799.0  NaN         NaN   \n 1       3.930583e+10  4.324911e+09 2017-01-01   369.0  NaN         NaN   \n 2       3.419099e+10  4.324911e+09 2017-01-01   189.0  NaN         NaN   \n 3       3.898633e+10  4.324911e+09 2017-01-01   169.0  NaN         NaN   \n 4       4.271359e+06  4.324911e+09 2017-01-01    78.0  NaN         NaN   \n ...              ...           ...        ...     ...  ...         ...   \n 102074           NaN           NaN        NaT     NaN  NaN         NaN   \n 102075           NaN           NaN        NaT     NaN  NaN         NaN   \n 102076           NaN           NaN        NaT     NaN  NaN         NaN   \n 102077           NaN           NaN        NaT     NaN  NaN         NaN   \n 102078           NaN           NaN        NaT     NaN  NaN         NaN   \n \n         Unnamed: 6  \n 0              NaN  \n 1              NaN  \n 2              NaN  \n 3              NaN  \n 4              NaN  \n ...            ...  \n 102074         NaN  \n 102075         NaN  \n 102076         NaN  \n 102077         NaN  \n 102078         NaN  \n \n [102079 rows x 7 columns],\n                 会员ID           订单号       提交日期    订单金额  NaN  Unnamed: 5  \\\n 0       3.922969e+10  4.338764e+09 2018-01-01  3646.0  NaN         NaN   \n 1       3.929367e+10  4.338764e+09 2018-01-01  3999.0  NaN         NaN   \n 2       3.505965e+10  4.338764e+09 2018-01-01    10.1  NaN         NaN   \n 3       1.084397e+06  4.338770e+09 2018-01-01   828.0  NaN         NaN   \n 4       3.349915e+06  4.338770e+09 2018-01-01  3758.0  NaN         NaN   \n ...              ...           ...        ...     ...  ...         ...   \n 163119           NaN           NaN        NaT     NaN  NaN         NaN   \n 163120           NaN           NaN        NaT     NaN  NaN         NaN   \n 163121           NaN           NaN        NaT     NaN  NaN         NaN   \n 163122           NaN           NaN        NaT     NaN  NaN         NaN   \n 163123           NaN           NaN        NaT     NaN  NaN         NaN   \n \n         Unnamed: 6  \n 0              NaN  \n 1              NaN  \n 2              NaN  \n 3              NaN  \n 4              NaN  \n ...            ...  \n 163119         NaN  \n 163120         NaN  \n 163121         NaN  \n 163122         NaN  \n 163123         NaN  \n \n [163124 rows x 7 columns],\n                会员ID  会员等级  Unnamed: 2  Unnamed: 3\n 0            100090     3         NaN         NaN\n 1       10012905801     1         NaN         NaN\n 2       10012935109     1         NaN         NaN\n 3       10013498043     1         NaN         NaN\n 4       10014087899     4         NaN         NaN\n ...             ...   ...         ...         ...\n 154380       998138     3         NaN         NaN\n 154381       998298     1         NaN         NaN\n 154382       998571     4         NaN         NaN\n 154383       999563     4         NaN         NaN\n 154384       999951     1         NaN         NaN\n \n [154385 rows x 4 columns]]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1629180966885
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#去除异常值与缺失值\n",
        "for ind in sheet_datas[:-1]:                                        #enumerate() 函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标\n",
        "    sheet_datas[ind] = each_data.dropna()                       # 丢弃缺失值记录\n",
        "    sheet_datas[ind] = each_data[each_data['订单金额'] > 1]     # 丢弃订单金额<=1的记录\n",
        "    sheet_datas[inach_data in enumerate(shed]['max_year_date'] = each_data['提交日期'].max() # 增加一列最大日期值"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-15-fe70d8a7cdfc>, line 5)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-fe70d8a7cdfc>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    sheet_datas[inach_data in enumerate(shed]['max_year_date'] = each_data['提交日期'].max() # 增加一列最大日期值\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "通过for循环配合enumerate方法，获得每个可迭代元素的索引和具体值。由于处理缺失值和异常值只针对订单数据，因此sheet_datas通过索引实现不包含最后一个对象（即会员等级表）。\n",
        "* 直接将each_data使用dropna丢弃缺失值后的数据框替代原来sheet_datas中的数据框。\n",
        "* 使用each_data[each_data['订单金额']>1]来过滤出包含订单金额>1的记录数，然后替换原来sheet_datas中的数据框。\n",
        "* 最后一行代码的目的是在每个年份的数据中新增一列max_year_date，通过each_data['提交日期'].max()获取一年中日期的最大值，这样方便后续针对每年的数据分别做RFM计算，而不是针对4年的数据统一做RFM计算。\n",
        "  \n",
        "汇总所有数据："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 汇总所有数据\n",
        "data_merge = pd.concat(sheet_datas[:-1],axis=0)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
            "of pandas will change to not sort by default.\n",
            "\n",
            "To accept the future behavior, pass 'sort=False'.\n",
            "\n",
            "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
            "\n",
            "  \n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1629181006071
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "将4年的数据使用pd.concat方法合并为一个完整数据框data_merge，这样后续的所有计算都能基于数据框进行，而不用写循环代码段对每个年份的数据单独计算。 \n",
        "  \n",
        "获取各自年份数据："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data_merge['date_interval'] = data_merge['max_year_date'] - data_merge['提交日期']#计算各自年份的最大日期与每个行的日期的差，得到日期间隔\n",
        "data_merge['year'] = data_merge['提交日期'].dt.year#增加一段新的字段，为每个记录行发生的年份"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'max_year_date'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'max_year_date'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-33f1b638017a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_merge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_interval'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_merge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_year_date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata_merge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'提交日期'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#计算各自年份的最大日期与每个行的日期的差，得到日期间隔\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_merge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_merge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'提交日期'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myear\u001b[0m\u001b[0;31m#增加一段新的字段，为每个记录行发生的年份\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'max_year_date'"
          ]
        }
      ],
      "execution_count": 19,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "第1行代码实现计算各自年份的最大日期与每个行的日期的差，得到日期间隔。  \n",
        "第2行代码实现增加一段新的字段，为每个记录行发生的年份，使用data_merge['提交日期'].dt.year实现。\n",
        "  \n",
        "转换日期间隔为数字："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#将日期间隔转化成文字\n",
        "data_merge['date_interval'] = data_merge['date_interval'].apply(lambda x: x.days) "
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "代码是将data_merge['date_interval']的时间间隔转换为数值型计算对象，这里使用了apply方法。apply方法是对某个pandas对象（数据框或series）实现某个函数的功能。配合lamda实现的是，从data_merge['date_interval']取出每个字段值，然后获得字段值的days结果并返回。\n",
        "  \n",
        "按会员ID做汇总："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#按会员ID做汇总\n",
        "rfm_gb = data_merge.groupby(['year','会员ID'], as_index=False).agg({'date_interval':'min', #计算最近一次的订单时间\n",
        "                                                                  '提交日期':'count', #计算订单的频率\n",
        "                                                                 '订单金额':'sum'}) #计算订单的总金额"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "该代码实现的是基于年份和会员ID，分别做RFM原始值的聚合计算。  \n",
        "这里的分类汇总使用的是groupby方法，以year和会员ID为联合主键，设置as_index=False意味着year和会员ID不作为index列，而是普通的数据框结果列。后面的agg方法实际上是一个“批量”聚合功能的函数，它实现了对data_interval、提交日期、订单金额三列分别以min、count、sum做聚合计算的功能。否则，我们需要分别写3条groupby来实现3个聚合计算。\n",
        "  \n",
        "重命名列名："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#重命名列名\n",
        "rfm_gb.columns = ['year','会员ID','r','f','m']\n",
        "rfm_gb.head()#预览并打印"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>会员ID</th>\n      <th>r</th>\n      <th>f</th>\n      <th>m</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>2015</td>\n      <td>267</td>\n      <td>197</td>\n      <td>2</td>\n      <td>105.0</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>2015</td>\n      <td>282</td>\n      <td>251</td>\n      <td>1</td>\n      <td>29.7</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>2015</td>\n      <td>283</td>\n      <td>340</td>\n      <td>1</td>\n      <td>5398.0</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>2015</td>\n      <td>343</td>\n      <td>300</td>\n      <td>1</td>\n      <td>118.0</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>2015</td>\n      <td>525</td>\n      <td>37</td>\n      <td>3</td>\n      <td>213.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "   year  会员ID    r  f       m\n0  2015   267  197  2   105.0\n1  2015   282  251  1    29.7\n2  2015   283  340  1  5398.0\n3  2015   343  300  1   118.0\n4  2015   525   37  3   213.0"
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用rfm_gb.columns实现重命名操作，然后输出预览（前5条计算结果）"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "（5）确定RFM划分区间  \n",
        "在做RFM划分时，基本逻辑是分别对R、F、M做分箱或者离散化操作，然后才能得到得分离散化后的结果。而离散化本身有多种方法可选，由于我们要对数据做RFM离散化，因此需要先看下数据的基本分布状态。  \n",
        "  \n",
        "查看数据分布："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#查看数据分布\n",
        "desc_pd = rfm_gb.iloc[:,2:].describe().T#由于只针对rfm三列，因此使用iloc方法，选择从第3列（索引值为2）开始的字段，调用describe方法\n",
        "print(desc_pd)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      count         mean          std  min   25%    50%     75%       max\n",
            "r  148591.0   165.524043   101.988472  0.0  79.0  156.0   255.0     365.0\n",
            "f  148591.0     1.365002     2.626953  1.0   1.0    1.0     1.0     130.0\n",
            "m  148591.0  1323.741329  3753.906883  1.5  69.0  189.0  1199.0  206251.8\n"
          ]
        }
      ],
      "execution_count": 23,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "由于只针对rfm三列，因此使用iloc方法，选择从第3列（索引值为2）开始的字段，调用describe方法，后面的T做转置的目的，是为了更加直观的展示。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "从基本概要可以看出，汇总后的数据总共有14万条，r和m的数据分布相对较为离散，表现在min、25%、50%、75%和max的数据没有特别集中；而从f（购买频率）可以看出，大部分用户的分布都趋近于1，表现是从min到75%的分段值都是1，且mean（均值）为1.365。  \n",
        "离散化的方法比较多，我们应根据自身应用特点和场景进行选择。这里我们将选择25%和75%作为区间划分的2个边界值。  \n",
        "有一个问题在于，r和m本身能较好的区分用户特征，但f则无法区分（大量的用户只有1个订单）。针对该问题我们与业务部门进行了沟通，结论是由于行业属性（大家电）的原因，用户发生复购确实很少，1年购买1次是比较普遍（其中包含新客户以及老客户在当年的第1次购买），因此划分时可以使用2和5来作为边界：选择2是因为一般的业务部门认为当年购买2次及2次以上就可以被定义为复购用户（而非累计订单的数量计算复购用户）。选择5是因为业务部门认为普通用户购买5次已经是非常高的次数，超过该次数就属于非常高价值的用户群体。可以说，这个值是基于业务经验和日常数据报表而获得的。  \n",
        "  \n",
        "设置区间边界："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义区间边界\n",
        "r_bins = [-1,79,255,365] # 注意起始边界小于最小值\n",
        "f_bins = [0,2,5,130]\n",
        "m_bins = [0,69,1199,206252]"
      ],
      "outputs": [],
      "execution_count": 25,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "基于上述分析，得到区间边界的基本原则如下：  \n",
        "中间2个边界值：r和m是分别通过25%和75%的值来获取的，f是业务与数据部门定义的。最小值边界：比各个维度的最小值小即可。  \n",
        "最大值边界：大于等于各个维度的最大值即可。  \n",
        "\n",
        "上面的原则中，中间2个边界值以及最大边界值比较容易理解，最小值边界为什么要小于各个维度的最小值呢？这是由于，在边界上的数据归属有一个基本原则，要么属于区间左侧，要么属于区间右侧。例如，f_bins中的2处于边界上，要么属于左侧区间，要么属于右侧区间。在后续使用pd.cut方法中，对于自定义边界，实行的是左开右闭的原则，即数据属于右侧区间，f_bins中的2就属于右侧区间。  \n",
        "这种原则会带来一个问题——最左侧的值是无法划分为任何区间的。因此，在定义最小值时，一定要将最小值的边界值定义得比数据框中的最小值要小。否则，当数据中出现与最小值边界值相同甚至更小的值时，数据就无法被划分在正常目标的区间内。  \n",
        "例如，有一列数[1,2,3,4,5]，假如数据划分的区间边界是[1,3,5]，即划分为2份。其中的2、3倍划分到(1,3]区间中，4、5被分到(3,5]区间中，而1则无法划分到任何一个正常区间内。  \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "（6）计算RFM因子权重  \n",
        "在计算RFM组合得分时，我们可以直接将结果组合为一个新的分组，例如322/132。但在加权求和得到一个新的RFM得分指标时，则必须要确定一个权重值。如何确定RFM三个维度的权重呢？  \n",
        "这里面提供一个思路。其实在每个公司中，涉及到会员数据时，一般都会有会员体系，而会员体系中有一个维度，是衡量会员价值度高低的，这个维度是——会员等级。在指定会员等级时，各个公司都已经综合考虑到了多种与公司整体利益相关的因素，设置各种会员权益都与会员等级有关。例如，免运费门槛、优惠券使用、特殊商品优惠价格、会员活动和营销等。因此我们可以基于会员等级来确定RFM三者的权重，基本思路是，建立一个rfm三个维度与会员等级的分类模型，然后通过模型输出维度的权重。  \n",
        "  \n",
        "匹配会员等级和RFM得分："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# 匹配会员等级和rfm得分\n",
        "rfm_merge = pd.merge(rfm_gb,sheet_datas[-1],on='会员ID',how='inner')#使用merge方法合并两个数据框，关联主键是会员ID，匹配方式是内部匹配"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "将会员的订单数据与等级数据匹配，使用merge方法合并两个数据框，关联主键是会员ID，匹配方式是内部匹配。  \n",
        "  \n",
        "通过RF获得RFM因子得分："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# rf获得rfm因子得分\n",
        "clf = RandomForestClassifier()#调用随机森林分类起模型\n",
        "clf = clf.fit(rfm_merge[['r','f','m']],rfm_merge['会员等级'])#使用随机森林分类器模型在我们的数据上进行拟合\n",
        "weights = clf.feature_importances_   #返回'r','f','m'三部分权重\n",
        "print('feature importance:',weights)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/Users/caozhibin/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "feature importance: [0.38814067 0.00506875 0.60679058]\n"
          ]
        }
      ],
      "execution_count": 27,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "上述过程非常简单，先建立rf模型对象，然后将rfm三列作为特征，将会员等级作为目标输入模型中进行训练，最后通过模型的feature_importances_获得权重信息。结果如上。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "由上述结果可知，在这3个维度中，用户的等级首先侧重于会员的价值贡献度（实际订单的贡献），其次是新近程度，最后是频次。这种逻辑与很多公司的整体会员等级一致。例如某国内电商的会员等级，是基于历史累计订单金额进行升级，如果最近一段时间（例如1年内）没有购物，则会降低会员等级。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "（7）RFM计算过程  \n",
        "RFM分箱得分："
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# RFM分箱得分\n",
        "rfm_gb['r_score'] = pd.cut(rfm_gb['r'], r_bins, labels=[i for i in range(len(r_bins)-1,0,-1)])# 计算R得分\n",
        "rfm_gb['f_score'] = pd.cut(rfm_gb['f'], f_bins, labels=[i+1 for i in range(len(f_bins)-1)])# 计算F得分\n",
        "rfm_gb['m_score'] = pd.cut(rfm_gb['m'], m_bins, labels=[i+1 for i in range(len(m_bins)-1)])# 计算M得分"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "每个rfm的过程使用了pd.cut方法，基于自定义的边界区间进行划分，labels用来显示每个离散化后的具体值。F和M的规则是值越大，等级越高；而R的规则是值越小，等级越高。因此关于R的labels的规则与F和M相反。在labels指定时需要注意，4个区间的结果是划分为3份，因此labels的数量上通过减1实现边界数量与区间数量的平衡，而i+1则实现了区间从1开始，而不是0。\n",
        "  \n",
        "计算总得分：  \n",
        "**方法1  加权得分**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#方法一：加权得分\n",
        "rfm_gb = rfm_gb.apply(np.int32) # cate转数值\n",
        "rfm_gb['rfm_score'] = rfm_gb['r_score'] * weights[0] + rfm_gb['f_score'] * weights[1] + rfm_gb['m_score'] * weights[2]\n"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "代码中，用rfm_gb方法将每个值转换为np.int32类型，否则上面pd.cut的实现结果是类别型结果。然后将rfm三列分别乘以权重，得到新的rfm加权得分。\n",
        "  \n",
        "**方法2  RFM组合**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#方法二：RFM组合\n",
        "rfm_gb['r_score'] = rfm_gb['r_score'].astype(np.str)#3列使用astype方法将数值型转换为字符串类型，然后使用pandas的字符串处理库中str的cat方法做字符串合并\n",
        "rfm_gb['f_score'] = rfm_gb['f_score'].astype(np.str)\n",
        "rfm_gb['m_score'] = rfm_gb['m_score'].astype(np.str)\n",
        "\n",
        "rfm_gb['rfm_group'] = rfm_gb['r_score'].str.cat(rfm_gb['f_score']).str.cat(rfm_gb['m_score'])"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "这种方式是传统的做会员分组的方式。目标是将3列作为字符串组合为新的分组。  \n",
        "代码中，现针对3列使用astype方法将数值型转换为字符串类型，然后使用pandas的字符串处理库中str的cat方法做字符串合并，该方法可以将右侧的数据合并到左侧，再连续使用两个str.cat方法得到总的R、F、M字符串组合。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$ 关于pandas的str方法 $$  \n",
        "这里str库中cat方法，用于字符串对象合并，语法如下：  \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "参数介绍：  \n",
        "others：要合并的另外一个对象（右侧对象），如果为空，则将左侧对象进行组合。  \n",
        "sep：合并的分隔符，默认为空，可自定义，例如“，”、“；”等。  \n",
        "na_rep：如果遇到NA（缺失值）时如何处理，默认为忽略。  \n",
        "需要注意的是：该方法用于对series做组合，而不能是数据框，适用于一维数据或者字符串。  \n",
        "举例：将左侧对象进行组合  \n",
        "输入输出如下。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.Series(['a', 'b', 'c']).str.cat(['A', 'B', 'C'], sep = ';' )"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "0    a;A\n1    b;B\n2    c;C\ndtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "（8）保存RFM结果到Excel"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#保存RFM结果到excel\n",
        "rfm_gb.to_excel('sales_rfm_score1.xlsx')# 保存数据为Excel"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用数据框的to_excel方法导出到文件。结果如图所示。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "image.png![image.png](attachment:image.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5、案例数据结论\n",
        "（1）基于图形的交互式分析  \n",
        "重点人群分布：先通过Excel柱形图做简单分析，在整个分组中，212群体的用户是相对集中且变化最大的。  \n",
        "通过图XX1可以发现，从2016年到2017年用户群体数量变化不大，但到2018年增长了近一倍。因此，这部分人群将作为重点分析人群。    \n",
        "重点分组分布：除了212人群外，图XX1还显示了312、213、211及112人群都在各个年份占据很大数量，虽然各自规模不大，但组合起来的总量超过212本身。因此，后期也要重点做分析。将阈值设置为2000以上，如图XX2中显示，很多分组非常少的人群减少了很多，说明人群数量比较少的组别非常多。  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "XX1.png![XX1.png](attachment:XX1.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "image (1).png![image%20%281%29.png](attachment:image%20%281%29.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "XX2.png![XX2.png](attachment:XX2.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "（2）基于RFM分组结果的分析  \n",
        "通过RFM分组的Excel结果数据，我们将更进一步确定要分析的主要目标群体。  \n",
        "我们打开导出的sales_rfm_score.xlsx文件，然后建立数据透视表。  \n",
        "步骤为：  \n",
        "单击Excel顶部菜单栏的“插入--数据透视表”，在弹窗的窗口中单击“确定”按钮，如图所示  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "image (2).png![image%20%282%29.png](attachment:image%20%282%29.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "在新建的sheet视图中，进行如下设置：  \n",
        "* 将rfm_group拖入数据透视表字段区域中的“行”区块\n",
        "* 将会员ID拖入数据透视表字段区域中的“值”区块\n",
        "* 单击会员ID项\n",
        "* 在弹出的窗口中选择“值字段设置”\n",
        "* 在弹窗中选择“计算类型”为“计数”\n",
        "* 单击“确定”按钮\n",
        "  \n",
        "到此，数据就以RFM分组为主题，以用户数量作为分类汇总了，如图所示"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "image (3).png![image%20%283%29.png](attachment:image%20%283%29.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "鼠标左键单击“计数项：会员ID”中的任意数值，单击顶部的排序功能，按从大到小排序。如图所示。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "image (4).png![image%20%284%29.png](attachment:image%20%284%29.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "排序后发现，会员在所有分组的分布是不均匀的，我们需要按百分数进行汇总显示，这样可以知道每个分组的占比。在透视表中的“计数项：会员ID”列单击任意数值，然后单击右键，在弹出的菜单中选择“值显示方式”，从右侧菜单中选择“父行汇总的百分比”，如图所示。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "image (5).png![image%20%285%29.png](attachment:image%20%285%29.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "设置完成后，我们对分区用户量进行累计求和，最后发现前9个分组的用户数量占比接近96%，如图所示"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "image (6).png![image%20%286%29.png](attachment:image%20%286%29.png)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "因此，我们需要把分析重点，放在这9组人群上。  \n",
        "  \n",
        "（3）RFM用户特征分析\n",
        "经过上面的分析，我们得到了要分析的重点客户群体。可根据用户的量级分为两类：\n",
        "第1类是用户群体占比超过10%的群体；  \n",
        "第2类是占比在个位数的群体。  \n",
        "这两类人由于量级不同，因此需要分别有针对性的策略场景。  \n",
        "除此以外，我们还会增加第3类人群，虽然从用户量级上偏小，但是单个人的价值度非常高。  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "**第1类人群**：占比超过10%的群体。  \n",
        "由于这类人群基数大，必须采取批量操作和运营的方式落地运营策略，一般需要通过系统或产品实现，而不能主要依赖于人工。  \n",
        "212：可发展的一般性群体。这类群体购买新进度和订单金额一般，且购买频率低，考虑到其最大的群体基础，以及在新进度和订单金额上都还可以，因此可采取常规性的礼品兑换和赠送购物社区活动、签到、免运费等手段，维持并提升其消费状态。  \n",
        "211：可发展的低价值群体。这类群体相对于212群体，在订单金额上表现略差，因此在211群体策略的基础上，可以增加与订单相关的刺激措施，例如组合商品优惠券，发送积分购买商品等。  \n",
        "312：有潜力的一般性群体。这类群体购买新进度高，说明最近一次购买发生在很短时间之前，群体对于公司尚有比较熟悉的接触渠道和认知状态，购物频率低，说明对网站的忠诚度一般，订单金额处于中等层级，说明其还具有可提升的空间，因此可以借助其最近购买的商品，为其定制一些与上次购买相关的商品，通过向上销售等策略提升购买频次和订单金额。  \n",
        "112：可挽回的一般性群体。这类群体购买新进度较低，说明距离上次购买时间较长，很可能用户已经处于沉默或预流失流失阶段；购买频率低，说明对网站的忠诚度一般，订单金额处于中等层级，说明其还可能具有可提升的空间，因此对这部分群体的策略，首先是通过多种方式（例如邮件短信等）触达客户并挽回，然后通过针对流失客户的专享优惠（例如流失用户专享优惠券）措施促进其消费，在此过程中可增加接触频次和刺激力度的方式，增加用户的回访、复购以及订单价值回报。  \n",
        "213：可发展的高价值群体。这类人群发展的重点是提升购物频率，因此可指定不同的活动或事件来触达用户，促进其回访和购买，例如不同的节日活动，每周新品推送，高价值客户专享商品等。  \n",
        "  \n",
        "**第2类人群**：占比为1%~10%的群体，这部分人群数量适中，在落地时无论是产品还是人工都可接入。  \n",
        "311：有潜力的低价值群体。这部分用户与211群体类似，但在购物新进度上更好，因此对其可采取相同的策略。除此以外，在这类群体的最近接触渠道上，可以增加营销或广告资源投入，通过这些渠道再次将客户引入网站完成消费。  \n",
        "111：这是一类在各个维度上都比较差的客户群体，一般情况下会在其他各个群体策略和管理都落地后才考虑他们。主要策略是先通过多种策略挽回客户，然后为客户推送与其类似的其他群体，或者当前热销的商品或折扣非常大的商品。在刺激消费时，可根据其消费水平、品类等情况，有针对性的设置商品暴露条件，先在优惠券及优惠商品的综合刺激下，使其实现消费，再考虑消费频率以及订单金额的提升。  \n",
        "313：有潜力的高价值群体。这类群体的消费新进度高且订单金额高，但购买频率低，因此只要提升其购买频次，用户群体的贡献价值就会倍增。提升购买频率上，除了在其最近一次的接触渠道上增加曝光外，与最近一次渠道相关的其他关联访问渠道也要考虑增加营销资源，另外213中的策略也要组合应用其中。  \n",
        "113：可挽回的高价值群体，这类群体与112群体类似，但订单金额贡献更高，因此除了应用112中的策略外，可增加部分人工的参与来挽回这些高价值客户，例如线下访谈，客户电话沟通等。  \n",
        "  \n",
        "**第3类群体**：占比非常少，但却是非常重要的群体。  \n",
        "333：绝对忠诚的高价值群体。虽然用户绝对数量只有355，但由于其各方面表现非常突出，因此可以倾斜更多的资源，例如设计VIP服务、专享服务、绿色通道等。另外针对这部分人群的高价值附加服务的推荐，也是提升其价值的重点策略。  \n",
        "233、223、133：一般性的高价值群体。这类群体的主要着手点是提升新近购买度，及促进其实现最近一次的购买，可通过电话、客户拜访、线下访谈、微信、电子邮件等方式，直接建立用户挽回通道，以挽回这部分高价值用户。  \n",
        "322、323、332：有潜力的普通群体。这类群体最近刚完成购买，需要提升的是购买频次及购买金额。因此可通过交叉销售、个性化推荐、向上销售、组合优惠券、打包商品销售等策略，提升其单次购买的订单金额，及促进其重复购买。  \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6、案例应用和部署\n",
        "针对上述得到的分析结论，会员部门采取了一下措施：  \n",
        "分别针对3类群体，按照公司实际运营需求和当前目标，制定了不同的群体落地的排期。  \n",
        "录入数据库的RFM得分数据已经应用到其他数据模型中，成为建模输入的关键维度特征之一。  \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7、案例注意点\n",
        "本案例中有一下几点需要特别关注的：  \n",
        "* 不同品类、行业对于RFM的依赖度是有差异的，即使是一个公司，在不同的发展阶段和周期下，3个维度的优先级上也有调整。就一般性的经验而言，大家电等消费周期较长的行业，R和M会更重要一些；快消品等消费周期短且快的行业，更看重R和F。具体还是要根据当前运营需求与业务部门沟通。\n",
        "* 对R、F、M区间的划分是一个离散化的过程，具体需要划分为几个区间，需要与业务方确认。本案例是划分为3个区间，这样的结果对于业务分析而言，略有点多。这意味着业务方需要制定十几套甚至更多的策略。如果业务方要求简略，也可以划分为2个区间，这样分出来的组别最多有8组，策略制定会更加简单。但是，具体是划分为2个还是3个，取决于当前业务方有多少资源可以投入到这个事情中来。\n",
        "* R、F、M的权重打分，除了案例中提到的建模方法外，结合业务经验的专家打分法也是常用的思路。例如，结合AHP层次分析法进行打分，这样出来的权重结果会更加科学、严谨。\n",
        "* 虽然订单数据库中的数据质量相对较高，但可能由于数据采集、数据库同步、ETL、查询、误操作等问题，还是会导致NA值的出现，而NA值的处理非常重要。\n",
        "* R、F、M三个维度的处理（包括计算、离散化、组合、转换）之前都需要注意期数据类型和格式，尤其是有关时间项的转换操作应提前完成。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8、案例延伸思考\n",
        "利用RFM模型划分用户群体并做价值度分析，是统计分析非常基础且有效的方法。该模型几乎用不到任何专业的统计分析和挖掘只是，只需要具有基本的数据清洗、处理和转换技能即可完成，因此几乎是各个企业都会用到的模型。更重要的是，该模型原理简单，业务方理解和应用起来非常容易入手，可大大提高部署落地的可能性。  \n",
        "结合本节案例，有一下几个值得思考的问题：  \n",
        "（1）按照R、F、M三个维度进行穷尽，应该有3*3*3=27中可能性，但是为什么结果只有26种？  \n",
        "（2）不同周期下，R、F、M权重会发生改变，那么运营结果是否有可比性和连续性？  \n",
        "（3）RFM模型可以作为模型分析方法，也可以作为数据预处理方法，基于不同的维度，通过计算组合得分或加权得分的方式获得新的数据，这是一种数据降维的有效方法。使用组合得分方法和加权得分方法得到的两种降维方法，在后续应用中，有什么不同呢？  \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 六、致谢\n",
        "感谢宋天龙老师的大力支持，本章内容部分参考宋天龙老师的《Python数据分析与数据化运营》。\n",
        "（完）"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}